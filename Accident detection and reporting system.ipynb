{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e37914d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2     # for capturing videos\n",
    "import math \n",
    "import geocoder\n",
    "import requests\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from twilio.rest import Client\n",
    "from geopy.geocoders import Nominatim\n",
    "from keras.preprocessing import image   # for preprocessing the images\n",
    "import numpy as np    # for mathematical operations\n",
    "from keras.utils import np_utils\n",
    "from matplotlib import pyplot as plt \n",
    "from skimage.transform import resize   # for resizing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68a13d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "cap = cv2.VideoCapture(\"D:/mini/Accidents.mp4\")   # capturing the video from the given path\n",
    "frameRate = cap.get(5) #frame rate\n",
    "x=1\n",
    "while(cap.isOpened()):\n",
    "    frameId = cap.get(1) #current frame number\n",
    "    ret, frame = cap.read()\n",
    "    if (ret != True):\n",
    "        break\n",
    "    if (frameId % math.floor(frameRate) == 0):\n",
    "        #filename =\"%d.jpg\" % count;count+=1\n",
    "        cv2.imwrite(\"D:/mini/fra/%d.jpg\" % count, frame)\n",
    "        count+=1\n",
    "cap.release()\n",
    "print (\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3e8a9c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1664be7cfd0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = plt.imread('D:/mini/fra/0.jpg')   # reading image using its name\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51cfa6e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_ID</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Image_ID  Class\n",
       "0    0.jpg      1\n",
       "1    1.jpg      1\n",
       "2    2.jpg      1\n",
       "3    3.jpg      1\n",
       "4    4.jpg      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('D:/mini/mapping.csv')     # reading the csv file\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c688dddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [ ]     # creating an empty array\n",
    "for img_name in data.Image_ID:\n",
    "    img = plt.imread('D:/mini/fra/' + img_name)\n",
    "    X.append(img)  # storing each image in array X\n",
    "X = np.array(X)    # converting list to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "857b09a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.Class\n",
    "dummy_y = np_utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c66ddd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = []\n",
    "for i in range(0,X.shape[0]):\n",
    "    a = resize(X[i], preserve_range=True, output_shape=(224,224)).astype(int)      # reshaping to 224*224*3\n",
    "    image.append(a)\n",
    "X = np.array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6776e412",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import preprocess_input\n",
    "X = preprocess_input(X,data_format=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11be3d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, dummy_y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e6e4465",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dense, InputLayer, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bfe0bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe2feb0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 31s 6s/step\n",
      "3/3 [==============================] - 13s 3s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((155, 7, 7, 512), (67, 7, 7, 512))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = base_model.predict(X_train)\n",
    "X_valid = base_model.predict(X_valid)\n",
    "X_train.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77bb546b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(155, 7*7*512)      # converting to 1-D\n",
    "X_valid = X_valid.reshape(67, 7*7*512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f641ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = X_train/X_train.max()      # centering the data\n",
    "X_valid = X_valid/X_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "535a32ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(InputLayer((7*7*512,)))    # input layer\n",
    "model.add(Dense(units=1024, activation='sigmoid')) # hidden layer\n",
    "model.add(Dense(2, activation='softmax'))    # output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72afb080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 1024)              25691136  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 2050      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,693,186\n",
      "Trainable params: 25,693,186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6d48cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60a536ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 2s 215ms/step - loss: 0.7984 - accuracy: 0.5742 - val_loss: 0.7060 - val_accuracy: 0.6119\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 102ms/step - loss: 0.3502 - accuracy: 0.8065 - val_loss: 0.7449 - val_accuracy: 0.7015\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 101ms/step - loss: 0.2236 - accuracy: 0.9419 - val_loss: 0.7387 - val_accuracy: 0.7313\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.1453 - accuracy: 0.9226 - val_loss: 0.7725 - val_accuracy: 0.7015\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 101ms/step - loss: 0.0939 - accuracy: 0.9935 - val_loss: 0.7765 - val_accuracy: 0.7612\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.0696 - accuracy: 0.9935 - val_loss: 0.7856 - val_accuracy: 0.7164\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.0455 - accuracy: 1.0000 - val_loss: 0.7896 - val_accuracy: 0.7313\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 0.0365 - accuracy: 1.0000 - val_loss: 0.7738 - val_accuracy: 0.7463\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 103ms/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 0.7587 - val_accuracy: 0.7463\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 0.0236 - accuracy: 1.0000 - val_loss: 0.7641 - val_accuracy: 0.7761\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 104ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.7732 - val_accuracy: 0.7761\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.7813 - val_accuracy: 0.7910\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.7900 - val_accuracy: 0.7612\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 101ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.7951 - val_accuracy: 0.7612\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 104ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.7956 - val_accuracy: 0.7761\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 103ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.7977 - val_accuracy: 0.7761\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.8004 - val_accuracy: 0.7612\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.8032 - val_accuracy: 0.7612\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.8044 - val_accuracy: 0.7612\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.8094 - val_accuracy: 0.7761\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.8163 - val_accuracy: 0.7761\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.8196 - val_accuracy: 0.7761\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 1s 113ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.8218 - val_accuracy: 0.7761\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.8249 - val_accuracy: 0.7761\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.8263 - val_accuracy: 0.7761\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.8273 - val_accuracy: 0.7761\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 1s 113ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.8285 - val_accuracy: 0.7761\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.8321 - val_accuracy: 0.7761\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 1s 103ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.8350 - val_accuracy: 0.7761\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 1s 103ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.8362 - val_accuracy: 0.7910\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.8386 - val_accuracy: 0.7910\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.8410 - val_accuracy: 0.7910\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 1s 113ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.8436 - val_accuracy: 0.7910\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.8467 - val_accuracy: 0.7910\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.8493 - val_accuracy: 0.7761\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 1s 102ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.8520 - val_accuracy: 0.8060\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 104ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.8551 - val_accuracy: 0.7910\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.8575 - val_accuracy: 0.7761\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 104ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.8582 - val_accuracy: 0.8060\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 101ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.8587 - val_accuracy: 0.8209\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 104ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.8609 - val_accuracy: 0.8209\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 1s 107ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8634 - val_accuracy: 0.8209\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.8658 - val_accuracy: 0.8209\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8699 - val_accuracy: 0.8209\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 1s 114ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.8739 - val_accuracy: 0.8060\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.8745 - val_accuracy: 0.8209\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.8756 - val_accuracy: 0.8209\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.8764 - val_accuracy: 0.8209\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8787 - val_accuracy: 0.8209\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8819 - val_accuracy: 0.8209\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8838 - val_accuracy: 0.8060\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 104ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8853 - val_accuracy: 0.8060\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8873 - val_accuracy: 0.8060\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 101ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8887 - val_accuracy: 0.8060\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8900 - val_accuracy: 0.8060\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 106ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8911 - val_accuracy: 0.8209\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8921 - val_accuracy: 0.8060\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 103ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8938 - val_accuracy: 0.8060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 102ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8976 - val_accuracy: 0.8060\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.9000 - val_accuracy: 0.7910\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 103ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.9016 - val_accuracy: 0.7910\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.9022 - val_accuracy: 0.7910\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.9035 - val_accuracy: 0.8209\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.9049 - val_accuracy: 0.8209\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.9064 - val_accuracy: 0.8060\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.9076 - val_accuracy: 0.8060\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.9089 - val_accuracy: 0.8060\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.9104 - val_accuracy: 0.8060\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.9128 - val_accuracy: 0.8060\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.9134 - val_accuracy: 0.8060\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.9150 - val_accuracy: 0.8060\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.9167 - val_accuracy: 0.8060\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.9187 - val_accuracy: 0.8060\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.9204 - val_accuracy: 0.8060\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.9225 - val_accuracy: 0.8209\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.9242 - val_accuracy: 0.8209\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.9257 - val_accuracy: 0.8060\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 9.7698e-04 - accuracy: 1.0000 - val_loss: 0.9279 - val_accuracy: 0.8060\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 9.5633e-04 - accuracy: 1.0000 - val_loss: 0.9288 - val_accuracy: 0.8060\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 9.3580e-04 - accuracy: 1.0000 - val_loss: 0.9301 - val_accuracy: 0.8060\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 9.1699e-04 - accuracy: 1.0000 - val_loss: 0.9308 - val_accuracy: 0.8060\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 8.9656e-04 - accuracy: 1.0000 - val_loss: 0.9322 - val_accuracy: 0.8060\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 8.8024e-04 - accuracy: 1.0000 - val_loss: 0.9344 - val_accuracy: 0.8060\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 104ms/step - loss: 8.6103e-04 - accuracy: 1.0000 - val_loss: 0.9354 - val_accuracy: 0.8060\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 1s 107ms/step - loss: 8.4261e-04 - accuracy: 1.0000 - val_loss: 0.9363 - val_accuracy: 0.8060\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 8.2751e-04 - accuracy: 1.0000 - val_loss: 0.9375 - val_accuracy: 0.8060\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 8.1107e-04 - accuracy: 1.0000 - val_loss: 0.9386 - val_accuracy: 0.8060\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 104ms/step - loss: 7.9388e-04 - accuracy: 1.0000 - val_loss: 0.9403 - val_accuracy: 0.8060\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 101ms/step - loss: 7.7735e-04 - accuracy: 1.0000 - val_loss: 0.9416 - val_accuracy: 0.8060\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 7.6299e-04 - accuracy: 1.0000 - val_loss: 0.9427 - val_accuracy: 0.8060\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 1s 113ms/step - loss: 7.5247e-04 - accuracy: 1.0000 - val_loss: 0.9444 - val_accuracy: 0.8060\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 7.3389e-04 - accuracy: 1.0000 - val_loss: 0.9462 - val_accuracy: 0.8060\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 7.2039e-04 - accuracy: 1.0000 - val_loss: 0.9471 - val_accuracy: 0.8060\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 7.0838e-04 - accuracy: 1.0000 - val_loss: 0.9484 - val_accuracy: 0.8060\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 1s 114ms/step - loss: 6.9543e-04 - accuracy: 1.0000 - val_loss: 0.9495 - val_accuracy: 0.8060\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 6.8253e-04 - accuracy: 1.0000 - val_loss: 0.9513 - val_accuracy: 0.8060\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 6.6938e-04 - accuracy: 1.0000 - val_loss: 0.9527 - val_accuracy: 0.8060\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 102ms/step - loss: 6.5918e-04 - accuracy: 1.0000 - val_loss: 0.9536 - val_accuracy: 0.8060\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 6.4699e-04 - accuracy: 1.0000 - val_loss: 0.9553 - val_accuracy: 0.8060\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 6.3533e-04 - accuracy: 1.0000 - val_loss: 0.9562 - val_accuracy: 0.8060\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16695f51cd0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train, y_train, epochs=100, validation_data=(X_valid, y_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79be5b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "487b383b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "videoFile = \"D:/mini/Accident-1.mp4\"\n",
    "cap = cv2.VideoCapture(videoFile)\n",
    "frameRate = cap.get(5) #frame rate\n",
    "x=1\n",
    "while(cap.isOpened()):\n",
    "    frameId = cap.get(1) #current frame number\n",
    "    ret, frame = cap.read()\n",
    "    if (ret != True):\n",
    "        break\n",
    "    if (frameId % math.floor(frameRate) == 0):\n",
    "        #filename =\"test%d.jpg\" % count;count+=1\n",
    "        cv2.imwrite(\"D:/mini/testfra/%d.jpg\" % count, frame)\n",
    "        count+=1\n",
    "cap.release()\n",
    "print (\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "688ce498",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('D:/mini/testfake.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c87fde32",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = []\n",
    "for img_name in test.Image_ID:\n",
    "    img = plt.imread('D:/mini/testfra/' + img_name)\n",
    "    test_image.append(img)\n",
    "test_img = np.array(test_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f31fc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = []\n",
    "for i in range(0,test_img.shape[0]):\n",
    "    a = resize(test_img[i], preserve_range=True, output_shape=(224,224)).astype(int)\n",
    "    test_image.append(a)\n",
    "test_image = np.array(test_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d83d6334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9, 7, 7, 512)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocessing the images\n",
    "test_image = preprocess_input(test_image, data_format=None)\n",
    "\n",
    "# extracting features from the images using pretrained model\n",
    "test_image = base_model.predict(test_image)\n",
    "test_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f980c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = test_image.reshape(9, 7*7*512)\n",
    "\n",
    "# zero centered images\n",
    "test_image = test_image/test_image.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9e856ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 103ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "535b6d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.5528764e-06 9.9999744e-01]\n",
      " [1.3264862e-04 9.9986744e-01]\n",
      " [1.3956531e-03 9.9860430e-01]\n",
      " [6.9788314e-04 9.9930215e-01]\n",
      " [1.8494178e-03 9.9815059e-01]\n",
      " [3.6817512e-01 6.3182497e-01]\n",
      " [6.6841060e-01 3.3158940e-01]\n",
      " [4.8006770e-01 5.1993233e-01]\n",
      " [7.4425542e-01 2.5574455e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0bf8c43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Accident\n",
      "No Accident\n",
      "No Accident\n",
      "No Accident\n",
      "No Accident\n",
      "No Accident\n",
      "Accident\n",
      "No Accident\n",
      "Accident\n"
     ]
    }
   ],
   "source": [
    "for i in range (0,9):\n",
    "    if predictions[i][0]<predictions[i][1]:\n",
    "        print(\"No Accident\")\n",
    "    else:\n",
    "        print(\"Accident\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8205e0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "geoLoc = Nominatim(user_agent=\"GetLoc\")\n",
    "g = geocoder.ip('me')\n",
    "locname = geoLoc.reverse(g.latlng)\n",
    "account_sid = \"AC824bdded46845c5782d657f9f41deadb\"\n",
    "auth_token = \"684558bb9bf868137a9c62b964677fe7\"\n",
    "client = Client(account_sid, auth_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "847ff914",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('D:/mini/Accident-1.mp4')\n",
    "i=0\n",
    "flag=0\n",
    "while(True):\n",
    "    ret,frame=cap.read()\n",
    "    if ret==True:\n",
    "        if predictions[int(i/15)%9][0]<predictions[int(i/15)%9][1]:\n",
    "            predict=\"No Accident\"\n",
    "        else:\n",
    "            predict=\"Accident\"\n",
    "            flag=1\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(frame,\n",
    "                predict,\n",
    "                (50, 50),\n",
    "                font, 1,\n",
    "                (0, 255, 255),\n",
    "                3,\n",
    "                cv2.LINE_4)\n",
    "        cv2.imshow('Frame', frame)\n",
    "        i=i+1\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "if flag==1:\n",
    "    client.messages.create(\n",
    "                 body=\"Accident detected in \"+locname.address,\n",
    "                 from_= +13465507660,\n",
    "                 to= +919390523520)\n",
    "\n",
    "# release the cap object\n",
    "cap.release()\n",
    "# close all windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d9f608",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aeb752d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
